{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import everygrams\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from typing import List, Generator, Optional, Tuple, Union\n",
    "from sklearn.utils.extmath import softmax\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I thought you were in a meeting--? &lt;BR&gt; I am. ...</td>\n",
       "      <td>[u'drama', u'romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you sure you're okay?  You're pale. &lt;BR&gt; I...</td>\n",
       "      <td>[u'drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Go on! Get out! &lt;BR&gt; Mom look don't say anythi...</td>\n",
       "      <td>[u'comedy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I could have lost my fucking hands. &lt;BR&gt; That ...</td>\n",
       "      <td>[u'mystery', u'thriller']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stick with me on this Gloria.  I need you... &lt;...</td>\n",
       "      <td>[u'crime', u'thriller']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie                                           dialogue  \\\n",
       "id                                                             \n",
       "0       0  I thought you were in a meeting--? <BR> I am. ...   \n",
       "1       1  Are you sure you're okay?  You're pale. <BR> I...   \n",
       "2       2  Go on! Get out! <BR> Mom look don't say anythi...   \n",
       "3       3  I could have lost my fucking hands. <BR> That ...   \n",
       "4       4  Stick with me on this Gloria.  I need you... <...   \n",
       "\n",
       "                       genres  \n",
       "id                             \n",
       "0      [u'drama', u'romance']  \n",
       "1                  [u'drama']  \n",
       "2                 [u'comedy']  \n",
       "3   [u'mystery', u'thriller']  \n",
       "4     [u'crime', u'thriller']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"genres\"] = train[\"genres\"].apply(eval)\n",
    "train.drop(columns=\"movie\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought you were in a meeting--? &lt;BR&gt; I am. ...</td>\n",
       "      <td>[drama, romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you sure you're okay?  You're pale. &lt;BR&gt; I...</td>\n",
       "      <td>[drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go on! Get out! &lt;BR&gt; Mom look don't say anythi...</td>\n",
       "      <td>[comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I could have lost my fucking hands. &lt;BR&gt; That ...</td>\n",
       "      <td>[mystery, thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stick with me on this Gloria.  I need you... &lt;...</td>\n",
       "      <td>[crime, thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             dialogue               genres\n",
       "id                                                                        \n",
       "0   I thought you were in a meeting--? <BR> I am. ...     [drama, romance]\n",
       "1   Are you sure you're okay?  You're pale. <BR> I...              [drama]\n",
       "2   Go on! Get out! <BR> Mom look don't say anythi...             [comedy]\n",
       "3   I could have lost my fucking hands. <BR> That ...  [mystery, thriller]\n",
       "4   Stick with me on this Gloria.  I need you... <...    [crime, thriller]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self) -> None:\n",
    "        self.orig_text_series = None\n",
    "        self.token_series = None\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.is_data_loaded = False\n",
    "        self.is_tokenized = False\n",
    "        self.ngram_range = None\n",
    "        \n",
    "    def load_data(self, text_series: pd.Series) -> None:\n",
    "        self.orig_text_series = text_series\n",
    "        self.is_data_loaded = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def _clean_text(text_series: pd.Series) -> None:\n",
    "        res = text_series.str.replace(r\"(<[^<>]+>|[^\\w\\s]+)\", \" \").str.lower()\n",
    "        return res\n",
    "    \n",
    "    def _lemmatize(self, tokens: List[str]) -> Generator[str, None, None]:\n",
    "        lemmatized_token_series = map(self.lemmatizer.lemmatize, tokens)\n",
    "        return lemmatized_token_series\n",
    "    \n",
    "    @staticmethod\n",
    "    def _remove_stopwords(lemmatized_tokens: Generator[str, None, None], stop_words: set) -> List[str]:\n",
    "        res = [t for t in lemmatized_tokens if t not in stop_words]\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def _every_grams(unigrams, ngram_range: Tuple[int, int] = (1, 1)):\n",
    "        res = [\" \".join(x) for x in everygrams(unigrams, *ngram_range)]\n",
    "        return res\n",
    "    \n",
    "    def tokenize(self, ngram_range: Tuple[int, int] = (1, 1), *, remove_stopwords: bool = True) -> None:\n",
    "        if not self.is_data_loaded:\n",
    "            raise Exception(\"text data is not loaded\")\n",
    "        text_series = self._clean_text(self.orig_text_series)\n",
    "        token_series = text_series.apply(word_tokenize)\n",
    "        unigrams = token_series.apply(self._lemmatize)\n",
    "        if remove_stopwords:\n",
    "            unigrams = unigrams.apply(lambda x: self._remove_stopwords(x, self.stop_words))\n",
    "        self.token_series = unigrams.apply(lambda x: self._every_grams(x, ngram_range))\n",
    "        self.is_tokenized = True\n",
    "        self.ngram_range = ngram_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_predict_proba(clf: \"classifier\", X: np.ndarray) -> np.ndarray:\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        pred = clf.predict_proba(X)\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        pred = softmax(clf.decision_function(X))\n",
    "    else:\n",
    "        raise AttributeError(f\"{repr(clf)} has no prediction methods\")\n",
    "    return pred\n",
    "\n",
    "def problem_predict(pred: pd.Series) -> np.ndarray:\n",
    "    problem_mask = pred.apply(lambda x: x.size == 0)\n",
    "    if np.any(problem_mask):\n",
    "        warnings.warn(f\"Empty prediction for {problem_mask.sum()} objects. Replaced with highest prob class.\")\n",
    "    problem_idx = np.where(problem_mask)[0]\n",
    "    return problem_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score(train: pd.DataFrame, clf: \"classifier\", *, n_splits: int = 5, tfidf_features: int = 20000, \n",
    "                    ngram_range: Tuple[int, int] = (1, 1), remove_stopwords: bool = True, proba_step: float = 0.005) -> dict:\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=tfidf_features,\n",
    "        tokenizer=lambda x: x,\n",
    "        preprocessor=lambda x: x,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )\n",
    "    tokenizer = Tokenizer()\n",
    "    \n",
    "    tokenizer.load_data(train[\"dialogue\"])\n",
    "    tokenizer.tokenize(ngram_range, remove_stopwords=remove_stopwords)\n",
    "    train[\"tokens\"] = tokenizer.token_series\n",
    "    train.drop(columns=\"dialogue\", inplace=True)\n",
    "    \n",
    "    cv_info = {}\n",
    "    probas = np.arange(0, 1 + 1**(-38), proba_step)\n",
    "    cv_scores = np.zeros((len(probas), n_splits))\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    for split_idx, (train_idx, test_idx) in enumerate(tqdm(kf.split(train), total=n_splits)):\n",
    "        train_ = train.loc[train_idx].explode(\"genres\", ignore_index=True)\n",
    "        test_ = train.loc[test_idx]\n",
    "        X_train_, y_train_ = train_[\"tokens\"], train_[\"genres\"]\n",
    "        X_train = tfidf.fit_transform(X_train_)\n",
    "        y_train = y_train_.values\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_test = test_[\"genres\"]\n",
    "        X_test = tfidf.transform(test_[\"tokens\"])\n",
    "        pred = safe_predict_proba(clf, X_test) \n",
    "        mlb = MultiLabelBinarizer(classes=clf.classes_)\n",
    "        y_true = mlb.fit_transform(test_[\"genres\"].apply(set))\n",
    "        for threshold_idx, threshold in enumerate(tqdm(probas, leave=False)):\n",
    "            y_pred = (pred >= threshold).astype(int)\n",
    "            score = f1_score(y_true, y_pred, average=\"samples\")\n",
    "            cv_scores[threshold_idx, split_idx] = score\n",
    "        \n",
    "    cv_scores = pd.DataFrame(cv_scores)\n",
    "    score_mean =  cv_scores.mean(axis=1)\n",
    "    score_std = cv_scores.std(axis=1)\n",
    "    cv_scores[\"threshold\"] = probas\n",
    "    cv_scores[\"mean\"] = score_mean\n",
    "    cv_scores[\"std\"] = score_std\n",
    "    cv_info[\"cv_scores\"] = cv_scores\n",
    "    \n",
    "    max_mean_idx = cv_scores[\"mean\"].argmax()\n",
    "    best_threshold, max_score, max_score_std = cv_scores[[\"threshold\", \"mean\", \"std\"]].iloc[max_mean_idx]\n",
    "    cv_info[\"best_threshold\"] = best_threshold\n",
    "    cv_info[\"max_score\"] = max_score\n",
    "    cv_info[\"max_score_std\"] = max_score_std\n",
    "    \n",
    "    cv_info[\"classifier\"] = clf\n",
    "    cv_info[\"preprocessing_params\"] = {\n",
    "        \"ngram_range\": ngram_range,\n",
    "        \"tfidf_features\": tfidf_features\n",
    "    }\n",
    "    \n",
    "    return cv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(clf, row, threshold):\n",
    "    return clf.classes_[row > threshold]\n",
    "\n",
    "\n",
    "def make_submission(train: pd.DataFrame, clf: \"classifier\", *, ngram_range: Tuple[int, int] = (1, 1), \n",
    "                    tfidf_features: int, threshold: float, file_suffix: Union[float, str] = \"\") -> None:\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=tfidf_features,\n",
    "        tokenizer=lambda x: x,\n",
    "        preprocessor=lambda x: x,\n",
    "        token_pattern=None,\n",
    "        lowercase=False\n",
    "    )\n",
    "    \n",
    "    train_ = train.explode(\"genres\", ignore_index=True)\n",
    "    X_train_, y_train_ = train_[\"tokens\"], train_[\"genres\"]\n",
    "    X_train = tfidf.fit_transform(X_train_)\n",
    "    y_train = y_train_.values\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.load_data(test[\"dialogue\"])\n",
    "    tokenizer.tokenize(ngram_range)\n",
    "    test[\"tokens\"] = tokenizer.token_series\n",
    "    X_test = tfidf.transform(test[\"tokens\"])\n",
    "    pred = safe_predict_proba(clf, X_test)\n",
    "    test[\"genres\"] = [get_classes(clf, i, threshold) for i in pred]\n",
    "    \n",
    "    problem_idx = problem_predict(test[\"genres\"])\n",
    "    if problem_idx.size:\n",
    "        test.iloc[problem_idx, test.columns.get_indexer([\"genres\"])] = clf.predict(X_test[problem_idx]).reshape(-1, 1)\n",
    "    file_name = f\"submission_{file_suffix}.csv\" if file_suffix else \"submission.csv\"\n",
    "    test[\"genres\"].str.join(sep=\" \").to_csv(file_name)\n",
    "    \n",
    "    return test[\"genres\"], clf, ngram_range, tfidf, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df8b854aae4003a2ac2d1e4825c668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=3, n_jobs=-1, solver=\"newton-cg\", dual=False)\n",
    "\n",
    "cv_info = cross_val_score(train, clf, ngram_range=(1, 1), tfidf_features=30000, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_scores':             0         1         2         3         4  threshold      mean  \\\n",
       " 0    0.167150  0.166330  0.166046  0.167259  0.166776      0.000  0.166712   \n",
       " 1    0.313490  0.313196  0.311029  0.313561  0.311150      0.005  0.312485   \n",
       " 2    0.377178  0.376030  0.371979  0.376112  0.374824      0.010  0.375224   \n",
       " 3    0.421178  0.420543  0.414865  0.418042  0.418097      0.015  0.418545   \n",
       " 4    0.455643  0.454869  0.448084  0.451167  0.452807      0.020  0.452514   \n",
       " ..        ...       ...       ...       ...       ...        ...       ...   \n",
       " 395  0.000000  0.000000  0.000000  0.000000  0.000000      1.975  0.000000   \n",
       " 396  0.000000  0.000000  0.000000  0.000000  0.000000      1.980  0.000000   \n",
       " 397  0.000000  0.000000  0.000000  0.000000  0.000000      1.985  0.000000   \n",
       " 398  0.000000  0.000000  0.000000  0.000000  0.000000      1.990  0.000000   \n",
       " 399  0.000000  0.000000  0.000000  0.000000  0.000000      1.995  0.000000   \n",
       " \n",
       "           std  \n",
       " 0    0.000521  \n",
       " 1    0.001282  \n",
       " 2    0.001997  \n",
       " 3    0.002496  \n",
       " 4    0.003036  \n",
       " ..        ...  \n",
       " 395  0.000000  \n",
       " 396  0.000000  \n",
       " 397  0.000000  \n",
       " 398  0.000000  \n",
       " 399  0.000000  \n",
       " \n",
       " [400 rows x 8 columns],\n",
       " 'best_threshold': 0.145,\n",
       " 'max_score': 0.6709298568763741,\n",
       " 'max_score_std': 0.0014587775938829247,\n",
       " 'classifier': LogisticRegression(C=3, n_jobs=-1, solver='newton-cg'),\n",
       " 'preprocessing_params': {'ngram_range': (1, 1), 'tfidf_features': 30000}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, fitted_clf, ngram_range, fitted_tfidf, threshold = make_submission(\n",
    "    train, clf=cv_info[\"classifier\"], **cv_info[\"preprocessing_params\"], threshold=cv_info[\"best_threshold\"],\n",
    "    file_suffix=round(10000 * cv_info[\"max_score\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.069233223439328"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(l) for l in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prophet:\n",
    "    def __init__(self, fitted_clf: \"classifier\", ngram_range: Tuple[int, int], fitted_tfidf: \"tfidf\", \n",
    "                 threshold: float) -> None:\n",
    "        self.clf = fitted_clf\n",
    "        self.threshold = threshold\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.tfidf = fitted_tfidf\n",
    "        \n",
    "    def predict(self, sentence: Union[str, pd.Series], *, print_tokens: bool = False) -> pd.Series:\n",
    "        if not isinstance(sentence, pd.Series):\n",
    "            sentence_series = pd.Series(sentence)\n",
    "        self.tokenizer.load_data(sentence_series)\n",
    "        self.tokenizer.tokenize(ngram_range)\n",
    "        token_series = self.tokenizer.token_series\n",
    "        if print_tokens:\n",
    "            print(token_series)\n",
    "        X = self.tfidf.transform(token_series)\n",
    "    \n",
    "        pred = safe_predict_proba(clf, X) \n",
    "    \n",
    "        res = pd.Series([get_classes(clf, i, threshold) for i in pred])\n",
    "    \n",
    "        problem_idx = problem_predict(res)\n",
    "        if problem_idx.size:\n",
    "            res.iloc[problem_idx] = clf.predict(X[problem_idx])\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet = Prophet(fitted_clf, ngram_range, fitted_tfidf, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [romance, sci-fi]\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet.predict(\"With great power comes great responsibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [drama]\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet.predict(\"\"\"\\\n",
    "Let me tell you something you already know. The world ain't all sunshine and rainbows. \n",
    "It's a very mean and nasty place and I don't care how tough you are it will beat you to your knees and keep you there \n",
    "permanently if you let it. You, me, or nobody is gonna hit as hard as life. But it ain't about how hard ya hit. \n",
    "It's about how hard you can get hit and keep moving forward. How much you can take and keep moving forward. \n",
    "That's how winning is done! Now if you know what you’re worth, go out and get what you’re worth, but you gotta be willing \n",
    "to take the hits and not pointing fingers, saying you ain’t where you wanna be because of him, or her, or anybody! \n",
    "Cowards do that and that ain’t you! You’re better than that!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
